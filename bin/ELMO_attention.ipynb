{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import MSELoss, L1Loss, SmoothL1Loss, CrossEntropyLoss\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Iterable, defaultdict\n",
    "\n",
    "from factslab.utility import load_glove_embedding\n",
    "from factslab.datastructures import ConstituencyTree, DependencyTree\n",
    "from factslab.pytorch.elmo_attention import Attention_mlp\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[\"The\", \"boy\", \"ran\", \"into\", \"the\", \"garden\", \".\"],\n",
    "     [\"Susan\", \"dies\"],\n",
    "     [\"He\", \"belived\", \"in\", \"humanity\"],\n",
    "     [\"The\", \"man\", \"stole\", \"his\", \"umbrealla\"]]\n",
    "     \n",
    "spans = [[2,3],\n",
    "        [1],\n",
    "        [1,2,3],\n",
    "        [2,3,4]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Attention_mlp(embedding_size=1024,\n",
    "                attention=True,attention_type=\"normal\",regression_hidden_sizes=[24,16], output_size=1,\n",
    "                 device=torch.device(type=\"cpu\"), batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward prop with full attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1464, -0.1593], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model(X[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward prop with span attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1166, -0.1467], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model(X[:2], spans[:2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## .   Model Parameters   ##############\n",
      "\n",
      "attention_map torch.Size([2, 1024])\n",
      "linear_maps.0.weight torch.Size([24, 1024])\n",
      "linear_maps.0.bias torch.Size([24])\n",
      "linear_maps.1.weight torch.Size([16, 24])\n",
      "linear_maps.1.bias torch.Size([16])\n",
      "linear_maps.2.weight torch.Size([1, 16])\n",
      "linear_maps.2.bias torch.Size([1])\n",
      "##############################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"########## .   Model Parameters   ##############\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape)\n",
    "print(\"##############################################\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (allennlp)",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
